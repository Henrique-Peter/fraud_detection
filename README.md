![image](https://github.com/Henrique-Peter/fraud_detection/blob/main/images/case_fraude.png)


## üìå Vis√£o Geral
Este projeto visa a identifica√ß√£o de compras digitais fraudulentas, que podem causar muita dor de cabe√ßa para os usu√°rios, al√©m de preju√≠zo para a institui√ß√£o financeira em quest√£o. Para isso, criaremos um modelo de Machine Learning que supere os resultados de um modelo previamente testado com os mesmos dados. O modelo antigo √© apresentado no dataset, ent√£o conseguimos avaliar o desempenho dele e depois comparar com o novo modelo treinado, apresentando a diferen√ßa n√£o s√≥ em m√©tricas como precision, f1-score e AUC-ROC, mas tamb√©m em valores financeiros dentro de um cen√°rio real, mostrando quanto a mais de lucro podemos gerar para a empresa. Utilizei algumas t√©cnicas como An√°lise Explorat√≥ria Bivariada para gerar algumas hip√≥teses e entender as rela√ß√µes das vari√°veis com o fato de ser ou n√£o fraude, tamb√©m utilizei o MLFlow na parte de ajuste dos hiperpar√¢metros para ter o melhor controle poss√≠vel sobre todos os testes que fiz, e por fim ainda apliquei o m√©todo SHAP para conseguir visualizar e explicar quais vari√°veis tiveram maior peso na decis√£o final do modelo.

## üíº Entendendo um pouco mais sobre fraudes em transa√ß√µes financeiras

### Import√¢ncia da Identifica√ß√£o de Fraudes
A identifica√ß√£o de transa√ß√µes fraudulentas √© uma preocupa√ß√£o central para institui√ß√µes financeiras em todo o mundo. Fraudes financeiras podem resultar em perdas significativas, afetando a lucratividade e a confian√ßa dos clientes na institui√ß√£o. A fraude ocorre quando transa√ß√µes s√£o realizadas de forma ilegal ou sem a autoriza√ß√£o adequada, e identificar esses casos √© crucial para proteger tanto os ativos financeiros da empresa quanto os de seus clientes.

### Impactos Financeiros
As transa√ß√µes fraudulentas t√™m um impacto financeiro direto e devastador. Para este projeto espec√≠fico, a institui√ß√£o financeira ganha 10% do valor de cada pagamento aprovado corretamente. No entanto, cada fraude aprovada resulta na perda de 100% do valor do pagamento. Isso significa que, para cada transa√ß√£o fraudulenta, a empresa n√£o apenas deixa de ganhar a comiss√£o de 10%, mas tamb√©m perde todo o valor transacionado. Essa din√¢mica ressalta a import√¢ncia de uma identifica√ß√£o eficaz das fraudes, pois mesmo um pequeno n√∫mero de fraudes pode rapidamente anular os lucros obtidos por muitas transa√ß√µes leg√≠timas.

### Exemplifica√ß√£o dos Impactos
Para ilustrar, considere o seguinte cen√°rio: se uma empresa aprova 100 transa√ß√µes leg√≠timas de 1.000 reais cada, ela ganha 10.000 reais (10% de 1.000 * 100). No entanto, se uma √∫nica transa√ß√£o fraudulenta de 1.000 reais for aprovada, a perda √© desse mesmo valor, anulando o ganho de 10 transa√ß√µes leg√≠timas. Portanto, a identifica√ß√£o e preven√ß√£o de fraudes s√£o fundamentais para manter a sa√∫de financeira da institui√ß√£o.

### Principais KPIs do Projeto

#### KPIs de Efici√™ncia e Efic√°cia do Modelo

*Taxa de Detec√ß√£o de Fraudes (Precision)*
- Descri√ß√£o: Percentual de transa√ß√µes identificadas como fraudulentas que realmente s√£o fraudes.
- F√≥rmula: (N√∫mero de Fraudes Corretamente Identificadas / N√∫mero Total de Transa√ß√µes Identificadas como Fraudes) * 100%

*Taxa de Cobertura de Fraudes (Recall)*
- Descri√ß√£o: Percentual de transa√ß√µes fraudulentas identificadas corretamente pelo sistema em rela√ß√£o ao total de fraudes.
- F√≥rmula: (N√∫mero de Fraudes Corretamente Identificadas / N√∫mero Total de Fraudes) * 100

*Acur√°cia do Modelo*
- Descri√ß√£o: Percentual de todas as transa√ß√µes (fraudulentas e n√£o fraudulentas) que foram classificadas corretamente.
- F√≥rmula: (N√∫mero de Transa√ß√µes Corretamente Classificadas / N√∫mero Total de Transa√ß√µes) * 100

*Taxa de Falsos Positivos*
- Descri√ß√£o: Percentual de transa√ß√µes n√£o fraudulentas que foram incorretamente classificadas como fraudes.
- F√≥rmula: (N√∫mero de Falsos Positivos / N√∫mero Total de Transa√ß√µes N√£o Fraudulentas) * 100

*Taxa de Falsos Negativos*
- Descri√ß√£o: Percentual de transa√ß√µes fraudulentas que n√£o foram detectadas pelo sistema.
- F√≥rmula: (N√∫mero de Falsos Negativos / N√∫mero Total de Transa√ß√µes Fraudulentas) * 100


#### KPIs Financeiros

*Valor Total de Fraudes Prevenidas*
- Descri√ß√£o: Quantidade de dinheiro que foi salva ao identificar e bloquear transa√ß√µes fraudulentas.
- F√≥rmula: Soma do valor de todas as transa√ß√µes fraudulentas bloqueadas

*Custo de Fraudes N√£o Detectadas*
- Descri√ß√£o: Quantidade de dinheiro perdida devido a fraudes que n√£o foram identificadas e bloqueadas.
- F√≥rmula: Soma do valor de todas as transa√ß√µes fraudulentas que passaram pelo sistema

*Taxa de Fraude (Fraud Rate)*
- Descri√ß√£o: Percentual de transa√ß√µes que s√£o fraudulentas em rela√ß√£o ao total de transa√ß√µes processadas.
- F√≥rmula: (N√∫mero Total de Transa√ß√µes Fraudulentas / N√∫mero Total de Transa√ß√µes) * 100

## üìä An√°lise do Modelo Inicial

O modelo inicial (`score_fraude_modelo`) definitivamente tem diversos pontos a serem melhorados, e podemos analisar isso por uma m√©trica super importante, a Curva ROC, como √© mostrada na imagem abaixo. 

1. Interpreta√ß√£o da AUC (√°rea sob a curva):

- Uma AUC de 0.73 indica que o modelo tem uma capacidade moderada de discriminar entre fraudes e n√£o fraudes. A AUC varia de 0 a 1, onde 1 representa um modelo perfeito e 0.5 representa um modelo sem poder discriminativo (equivalente a uma classifica√ß√£o aleat√≥ria).
- Com 0.73, o modelo atual √© melhor do que uma classifica√ß√£o aleat√≥ria, mas ainda h√° espa√ßo significativo para melhorias.

2. Curva ROC:

- A curva ROC em si mostra a rela√ß√£o entre a taxa de verdadeiros positivos (sensibilidade) e a taxa de falsos positivos (1 - especificidade) em diferentes limiares de classifica√ß√£o.
- A curva est√° acima da linha diagonal (linha de n√£o discrimina√ß√£o), o que √© bom, mas a inclina√ß√£o poderia ser mais acentuada para indicar uma melhor performance.

*Pontos a Considerar:*
- Melhoria do Modelo: Com uma AUC de 0.73, o modelo est√° acertando mais do que errando, mas √© crucial entender onde ele est√° falhando. Analisar casos espec√≠ficos de falsos positivos e falsos negativos pode ajudar a refinar o modelo.
- Balanceamento dos Dados: Precisamos certificar de que os dados de fraude e n√£o fraude est√£o balanceados ou precisaremos usar t√©cnicas de balanceamento para evitar vi√©s no treinamento.
- Ajuste de Hiperpar√¢metros: Ajustar os hiperpar√¢metros do modelo pode levar a uma melhor performance.
- Features Adicionais: Certamente partiremos para a engenharia de novas features ou a transforma√ß√£o de features existentes para melhorar a performance do modelo.

![image](https://github.com/Henrique-Peter/fraud_detection/blob/main/images/roc_auc.png)

## üõ† Pr√©-processamento 
O pr√©-processamento de dados √© crucial em projetos de Machine Learning. Utilizei o Pipeline do Scikit-learn para garantir efic√°cia e reprodutibilidade. 

*Considera√ß√µes:*
- Todos os valores da coluna `valor_compra` est√£o em d√≥lares;
- N√£o teremos a possibilidade de data leakage, ou seja, todos os dados que est√£o no dataframe inicial do projeto sempre ser√£o recebidos e calculados antes do evento de "Fraude" ocorrer.
   
*O que ser√° feito no pr√©-processamento:*
- Excluir a coluna `score_fraude_modelo`, visto que ela servia como modelo baseline, e agora n√£o ser√° mais usada;
- Excluir a coluna `data_compra` para n√£o adicionar a complexidade temporal citada durante a parte de an√°lise dos dados;
- Excluir a coluna `produto`, por ter uma alta cardinalidade (s√£o mais de 127 mil valores √∫nicos, dentro de 150 mil registros);
- Excluir a coluna `score_8` pois isso ajudar√° a diminuir o ru√≠do (coluna com valores com quase nenhuma distin√ß√£o entre fraude e n√£o fraude, n√£o agregando muito para o treinamento do modelo);
- Separar a coluna `categoria_produto` em menos valores √∫nicos, mantendo as 1000 categorias (aproximadamente 11% das categorias) que representam 85% das fraudes, e agrupando o restante das categorias como "Outros";
- Realizar algo parecido com a coluna `pais`, mantendo apenas Brasil e Argentina (BR e AR) por representarem mais de 97% dos registros, e agrupar o restante dos pa√≠ses como "Outros";
- Preencher os valores nulos de score com a mediana, por n√£o seguirem uma distribui√ß√£o normal;
- Preencher os valores nulos de `entrega_doc_2` com 0, visto que no in√≠cio do projeto a informa√ß√£o era que valores nulos seriam a mesma coisa que "n√£o entregou" (al√©m disso preciso mudar os valores "Y" e "N" das colunas `entrega_doc_2` e `entrega_doc_3` para 0 e 1, assim o modelo conseguir√° interpretar corretamente o que √© entrega ou n√£o);
- Criar uma feature `was_null` que indicar√° os registros de `entrega_doc_2` que eram nulos antes da transforma√ß√£o;
- Fazer target encoder na coluna `categoria_produto` devido √† alta cardinalidade (mesmo que eu diminua para 1001 valores √∫nicos, s√£o muitos valores). Al√©m disso, usar t√©cnica de cross validation junto com o encoder, pois como temos muitas categorias, n√£o queremos mais de uma com o mesmo valor (empatadas);
- Fazer one hot encoder nas demais vari√°veis categ√≥ricas.

## ü§ñ Modelagem e Avalia√ß√£o

Primeiramente eu treinei os seguintes modelos: Balanced RF, Light GBM, XGBoost e Decision Tree. Pelos resultados, optei por seguir com o Light GBM, e ent√£o usei o RandomizedSearchCV para otimizar os hiperpar√¢metros. As m√©tricas de avalia√ß√£o incluem: log-loss, precision, recall, f1-score e ROC-AUC .

## üìà Insights e Conclus√µes

Passando por todo o projeto, podemos resumir os resultados em 4 principais pontos, comparando o modelo baseline com o novo modelo treinado:

1. M√©tricas financeiras (considerando dados de teste)
- Threshold: passou de 73 para 57
- Ganhos: passou de USD 80330 para USD 86128
- Perdas: passou de USD 25353 para USD 18070
- Lucro: passou de USD 54977 para USD 68058

2. Matriz de confus√£o e taxas de fraude e aprova√ß√£o (considerando dados de teste)
- Falsos negativos: passou de 503 para 383 (diminuir esse quadrante da matriz √© especialmente importante, pois √© aquele que causa preju√≠zo dobrado para a institui√ß√£o, perdendo a comiss√£o de 10% e ainda tendo que pagar 100% do valor para o cliente)
- Taxa de fraude permaneceu a mesma (2%), enquanto a de aprova√ß√£o passou de 74% para 77%

3. M√©tricas de desempenho
- Log Loss: passou de 8.6 para 7.3 (diminuir essa m√©trica indica que o modelo est√° fazendo previs√µes melhores)
- Precis√£o: passou de 0.13 para 0.17 (indica que o novo modelo conseguiu classificar mais fraudes que realmente eram fraudes)
- Recall: passou de 0.67 para 0.75 (indica que o novo modelo conseguiu identificar melhor as fraudes que realmente eram fraudes)
- F1-score: passou de 0.22 para 0.27 (como o F1-score √© a m√©dia harm√¥nica da precis√£o e do recall, tendo aumentado ambos, essa m√©trica tamb√©m cresceu)
- ROC-AUC: passou de 0.73 para 0.85 (o novo modelo est√° conseguindo generalizar melhor, entendendo as diferen√ßas entre fraudes e n√£o fraudes)

4. O que realmente importa no fim do dia... qual o lucro a mais que foi gerado?
- Como calculado acima, considerando as m√©dias de compras por m√™s, e a m√©dia dos valores das compras, o modelo inicial, por ter uma raz√£o de lucro de 68%, conseguiria um lucro mensal de aproximadamente USD 221968. Enquanto o modelo novo, com uma raz√£o de lucro de 79%, conseguiria um lucro mensal de aproximadamente USD 257874
- Por m√™s, isso representa uma diferen√ßa de USD 35906, e por ano de USD 430872 a mais que a institui√ß√£o ir√° ganhar de lucro. Isso representa um aumento de lucros anuais em 16%.

Ou seja, o novo modelo treinado n√£o s√≥ melhora a capacidade de detec√ß√£o de compras fraudulentas, como tamb√©m aumenta consideravelmente os lucros da empresa.

## üöß Pr√≥ximos Passos

Os pr√≥ximos passos v√£o para um pouco al√©m do projeto em si, e aqui eu destaco dois principais pontos:

*Como voceÃÇ pode garantir que o desempenho do modelo no laboratoÃÅrio vai ser um proxy para o desempenho do modelo em producÃßaÃÉo?*

Garantir que o desempenho do modelo no laborat√≥rio seja um proxy para o desempenho do modelo em produ√ß√£o envolve v√°rias pr√°ticas e considera√ß√µes durante o desenvolvimento e a valida√ß√£o do modelo. Alguns exemplos pr√°ticos n√£o citados no projeto s√£o:

Dados Representativos:
- Assegurando que os dados de treinamento e teste sejam representativos do ambiente de produ√ß√£o. Isso inclui a mesma distribui√ß√£o de fraudes e n√£o fraudes, bem como caracter√≠sticas e padr√µes de comportamento dos usu√°rios.

Simula√ß√£o do Ambiente de Produ√ß√£o:
- Criando um ambiente de teste que simule o ambiente de produ√ß√£o, incluindo lat√™ncias, volumes de dados, e padr√µes de acesso.

Monitoramento Cont√≠nuo:
- Implementando um sistema de monitoramento para verificar o desempenho do modelo em produ√ß√£o. Monitorar m√©tricas de desempenho, como precis√£o, recall, F1-score e taxas de falsos positivos/negativos.
- Monitorar tamb√©m dados de entrada para detectar mudan√ßas na distribui√ß√£o dos dados que podem afetar o desempenho do modelo.

An√°lise de Erros:
- Realizar uma an√°lise detalhada dos casos de erro do modelo (tanto falsos positivos quanto falsos negativos) para entender suas limita√ß√µes e melhorar a robustez do modelo.

Atualiza√ß√£o Cont√≠nua do Modelo:
- Atualizar o modelo regularmente com novos dados e retrain√°-lo conforme as mudan√ßas nos padr√µes de comportamento e nas caracter√≠sticas das fraudes.

Teste de Estresse:
- Submetendo o modelo a testes de estresse para garantir que ele pode lidar com picos de carga e volumes de dados maiores sem degrada√ß√£o significativa do desempenho.


*O segundo ponto seria: Se o modelo precisar responder online, no menor tempo possiÃÅvel, o que isso mudaria no desenvolvimento?*

Infraestrutura de Baixa Lat√™ncia:
- Servidores de Alto Desempenho: Utilizando servidores com CPUs de alta performance e baixa lat√™ncia. LightGBM √© altamente eficiente em CPUs e pode n√£o precisar de GPUs.
- Infraestrutura Otimizada: Considerar o uso de servi√ßos de nuvem otimizados para machine learning, como Amazon SageMaker, Google AI Platform, ou Azure Machine Learning, que oferecem inst√¢ncias otimizadas para baixa lat√™ncia.

Deploy do Modelo:
- Servi√ßos de Infer√™ncia: Implementando o LightGBM como um servi√ßo de infer√™ncia, utilizando frameworks que suportam baixa lat√™ncia como Flask, FastAPI, ou microservi√ßos em Kubernetes.
- Serializa√ß√£o do Modelo: Salvar o modelo treinado em um formato eficiente como .txt ou .bin e carregar na mem√≥ria durante a infer√™ncia para reduzir o tempo de carregamento.

Monitoramento e Logging:
- Tempo de Resposta: Monitorar continuamente o tempo de resposta para identificar poss√≠veis gargalos e otimizar o desempenho.
- Logging Otimizado: Implementar logging eficiente para rastrear e depurar a performance sem adicionar sobrecarga significativa.
